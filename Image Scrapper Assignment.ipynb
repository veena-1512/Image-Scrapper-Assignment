{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "413adc3f-f771-47a5-8368-5a61333af272",
   "metadata": {},
   "source": [
    "Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cdebda-9892-477a-987b-5126f9010e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_youtube_urls(search_query, num_results=5):\n",
    "    base_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "    search_url = f\"{base_url}/results?q={search_query}\"\n",
    "\n",
    "    # Make an HTTP request to the YouTube search page\n",
    "    response = requests.get(search_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extract video URLs from the search results\n",
    "    video_urls = []\n",
    "    for result in soup.find_all('a', {'id': 'video-title'}, href=True):\n",
    "        video_url = base_url + result['href']\n",
    "        video_urls.append(video_url)\n",
    "\n",
    "        # Break the loop if we have collected the desired number of results\n",
    "        if len(video_urls) == num_results:\n",
    "            break\n",
    "\n",
    "    return video_urls\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    search_query = input(\"Enter the YouTube search query: \")\n",
    "    video_urls = get_youtube_urls(search_query)\n",
    "\n",
    "    if video_urls:\n",
    "        print(\"\\nFirst five video URLs:\")\n",
    "        for i, url in enumerate(video_urls, start=1):\n",
    "            print(f\"{i}. {url}\")\n",
    "    else:\n",
    "        print(\"No video URLs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb1b764-b4bc-478c-9635-7d94159ce5ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b7fc871-e0ed-4802-b1cd-153b102a949c",
   "metadata": {},
   "source": [
    "Q2. Write a python program to extract the URL of the video thumbnails of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3942de-66a7-49c5-9cf2-e0c20dad3308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_youtube_thumbnail_urls(search_query, num_results=5):\n",
    "    base_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "    search_url = f\"{base_url}/results?q={search_query}\"\n",
    "\n",
    "    # Make an HTTP request to the YouTube search page\n",
    "    response = requests.get(search_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extract video thumbnail URLs from the search results\n",
    "    thumbnail_urls = []\n",
    "    for result in soup.find_all('a', {'id': 'video-title'}, href=True):\n",
    "        video_url = base_url + result['href']\n",
    "\n",
    "        # Extract video page to get the thumbnail\n",
    "        video_page_response = requests.get(video_url)\n",
    "        video_page_soup = BeautifulSoup(video_page_response.text, 'html.parser')\n",
    "\n",
    "        # Find the thumbnail image URL\n",
    "        thumbnail_tag = video_page_soup.find('meta', {'property': 'og:image'})\n",
    "        if thumbnail_tag:\n",
    "            thumbnail_url = thumbnail_tag['content']\n",
    "            thumbnail_urls.append(thumbnail_url)\n",
    "\n",
    "        # Break the loop if we have collected the desired number of results\n",
    "        if len(thumbnail_urls) == num_results:\n",
    "            break\n",
    "\n",
    "    return thumbnail_urls\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    search_query = input(\"Enter the YouTube search query: \")\n",
    "    thumbnail_urls = get_youtube_thumbnail_urls(search_query)\n",
    "\n",
    "    if thumbnail_urls:\n",
    "        print(\"\\nFirst five video thumbnail URLs:\")\n",
    "        for i, url in enumerate(thumbnail_urls, start=1):\n",
    "            print(f\"{i}. {url}\")\n",
    "    else:\n",
    "        print(\"No video thumbnail URLs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ec2587-4375-43c5-9f4b-41a123630ada",
   "metadata": {},
   "source": [
    "Q3. Write a python program to extract the title of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d7d11c-df1a-4c0b-b61d-701479ba08cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_youtube_video_titles(search_query, num_results=5):\n",
    "    base_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "    search_url = f\"{base_url}/results?q={search_query}\"\n",
    "\n",
    "    # Make an HTTP request to the YouTube search page\n",
    "    response = requests.get(search_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extract video titles from the search results\n",
    "    video_titles = []\n",
    "    for result in soup.find_all('a', {'id': 'video-title'}, href=True):\n",
    "        video_title = result.text.strip()\n",
    "        video_titles.append(video_title)\n",
    "\n",
    "        # Break the loop if we have collected the desired number of results\n",
    "        if len(video_titles) == num_results:\n",
    "            break\n",
    "\n",
    "    return video_titles\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    search_query = input(\"Enter the YouTube search query: \")\n",
    "    video_titles = get_youtube_video_titles(search_query)\n",
    "\n",
    "    if video_titles:\n",
    "        print(\"\\nFirst five video titles:\")\n",
    "        for i, title in enumerate(video_titles, start=1):\n",
    "            print(f\"{i}. {title}\")\n",
    "    else:\n",
    "        print(\"No video titles found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1436a4c1-1915-467b-8c8b-2046817c33df",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f52e73f-9ea5-4376-9f94-093e9bb7a6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the YouTube search query:  first five videos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No video views found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_youtube_video_views(search_query, num_results=5):\n",
    "    base_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "    search_url = f\"{base_url}/results?q={search_query}\"\n",
    "\n",
    "    response = requests.get(search_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extract video views from the search results\n",
    "    video_views = []\n",
    "    for result in soup.find_all('span', {'class': 'style-scope ytd-video-meta-block'}, string=True):\n",
    "        # Check if the string contains 'views' to identify view counts\n",
    "        if 'views' in result.text:\n",
    "            views_text = result.text.strip().split()[0]  # Extract the view count part\n",
    "            video_views.append(views_text)\n",
    "\n",
    "        if len(video_views) == num_results:\n",
    "            break\n",
    "\n",
    "    return video_views\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    search_query = input(\"Enter the YouTube search query: \")\n",
    "    video_views = get_youtube_video_views(search_query)\n",
    "\n",
    "    if video_views:\n",
    "        print(\"\\nFirst five video views:\")\n",
    "        for i, views in enumerate(video_views, start=1):\n",
    "            print(f\"{i}. {views}\")\n",
    "    else:\n",
    "        print(\"No video views found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8368ee2-c7ab-42b9-a186-48aa6e51d2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184b46f4-3a31-4c8b-a704-22c6f46872e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c66f0c-f6ec-441b-82ff-47273456bc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
